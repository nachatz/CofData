{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from math import sqrt\n",
    "from sklearn import model_selection\n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Vectors Used as Input Features\n",
    "inp_vectors = pd.read_csv(\"rand_forest.csv\")\n",
    "# Read Vectors Used as Target Features\n",
    "target_data = pd.read_csv('properties.csv')\n",
    "# Prepare to Read Train and Testing Masks as Lists\n",
    "train_masks = []\n",
    "test_masks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate the Names of Cofs from Dataframe\n",
    "# Use for future alignment of Target and Input DB order\n",
    "db_cofs = inp_vectors[['cof']]\n",
    "# Create Single Dimentional Array\n",
    "db_cofs = np.squeeze(db_cofs.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate the Training Features from Names\n",
    "db_traindata = inp_vectors[['ASA_m^2/g','Density','LS','B','O','C','H',\n",
    "                        'Si','N','S','Ni','Zn','Cu','Co','F','P','Cl','V','Br']]\n",
    "# Convert to Arrays\n",
    "db_traindata = db_traindata.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in The Train and Test Masks from Seperate pkl Files\n",
    "# Stored in the './splits' directory\n",
    "for i in range(10):\n",
    "    # Read in Object from pkl\n",
    "    obj = pd.read_pickle(r'splits/split_run_{}.pkl'.format(i))\n",
    "    # Seperate Out Masks as Keys\n",
    "    train_masks.append(obj['masks']['train'])\n",
    "    test_masks.append(obj['masks']['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[46,\n",
       " 47,\n",
       " 291,\n",
       " 398,\n",
       " 221,\n",
       " 256,\n",
       " 374,\n",
       " 134,\n",
       " 368,\n",
       " 58,\n",
       " 166,\n",
       " 33,\n",
       " 297,\n",
       " 424,\n",
       " 300,\n",
       " 350,\n",
       " 364,\n",
       " 519,\n",
       " 279,\n",
       " 8,\n",
       " 425,\n",
       " 207,\n",
       " 365,\n",
       " 434,\n",
       " 70,\n",
       " 287,\n",
       " 14,\n",
       " 173,\n",
       " 447,\n",
       " 171,\n",
       " 205,\n",
       " 212,\n",
       " 0,\n",
       " 565,\n",
       " 67,\n",
       " 121,\n",
       " 520,\n",
       " 310,\n",
       " 399,\n",
       " 528,\n",
       " 223,\n",
       " 525,\n",
       " 513,\n",
       " 487,\n",
       " 418,\n",
       " 154,\n",
       " 75,\n",
       " 337,\n",
       " 347,\n",
       " 352,\n",
       " 187,\n",
       " 511,\n",
       " 11,\n",
       " 180,\n",
       " 174,\n",
       " 80,\n",
       " 542,\n",
       " 193,\n",
       " 293,\n",
       " 538,\n",
       " 254,\n",
       " 159,\n",
       " 438,\n",
       " 127,\n",
       " 318,\n",
       " 20,\n",
       " 392,\n",
       " 431,\n",
       " 2,\n",
       " 23,\n",
       " 334,\n",
       " 198,\n",
       " 483,\n",
       " 469,\n",
       " 59,\n",
       " 240,\n",
       " 367,\n",
       " 401,\n",
       " 234,\n",
       " 415,\n",
       " 162,\n",
       " 247,\n",
       " 54,\n",
       " 465,\n",
       " 73,\n",
       " 541,\n",
       " 29,\n",
       " 32,\n",
       " 170,\n",
       " 138,\n",
       " 504,\n",
       " 564,\n",
       " 277,\n",
       " 131,\n",
       " 239,\n",
       " 326,\n",
       " 168,\n",
       " 201,\n",
       " 194,\n",
       " 21,\n",
       " 420,\n",
       " 93,\n",
       " 429,\n",
       " 6,\n",
       " 83,\n",
       " 558,\n",
       " 42,\n",
       " 543,\n",
       " 147,\n",
       " 467,\n",
       " 151,\n",
       " 98,\n",
       " 257,\n",
       " 441]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj['ids_graphs_cold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_vectors_cold = inp_vectors.values[obj['ids_graphs_cold']]\n",
    "#X_train, X_test, Y_train, Y_test -> better naming convention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_vectors_warm = inp_vectors.values[obj['ids_graphs_warm']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(452, 20)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_vectors_warm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, remove the values in target that don't have valid graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Names from Targets and Inputs into lists\n",
    "# Then use set Overlap in order to determine values we don't need\n",
    "# Some are not present in splits because of Graph Bugs\n",
    "list1 = np.squeeze(target_data[['name']].values)\n",
    "list2 = db_cofs\n",
    "# valid_list is the list of overlapping (and thus valid) cofs\n",
    "valid_list = list(set(list1).intersection(list2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the targets from the Matrix Factorization paper\n",
    "target_data = target_data[['name','h2o_henry', 'h2s_henry', 'xe_henry', 'kr_henry', 'co2_0.001bar', 'o2_5bar', 'o2_140bar', 'co2_30bar', 'n2_0.001bar', 'n2_30bar', 'h2_77K_5bar', 'h2_77K_100bar', \n",
    "            'h2_298K_5bar', 'h2_298K_100bar', 'ch4_65bar', 'ch4_5.8bar']]\n",
    "# Convert to Arrays\n",
    "target_data = target_data.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seperation of warm and cold graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_data_cold = target_data[obj['ids_graphs_cold']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_data_warm = target_data[obj['ids_graphs_warm']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(452, 17)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_data_warm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list called removal, this will hold indeces we need to remove\n",
    "removal = []\n",
    "# Sift through all of the target data\n",
    "for i,cof in enumerate(target_data):\n",
    "    # If the name is not valid, then add the index to the removal list\n",
    "    if cof[0] not in valid_list:\n",
    "        removal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now use the numpy delete function in order to remove values at those indeces\n",
    "# Now all of the target data is what we would like to use!\n",
    "target_data = np.delete(target_data, removal, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, use the targets to produce an ordered set of input vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an empty list called sorted_cofs, which will hold indeces that we would like\n",
    "# to reorganize our list of training data to. \n",
    "sorted_cofs = []\n",
    "for name in list2:\n",
    "    # Find the index that we need to shift the current value to, based on the target organization\n",
    "    sorted_cofs.append(np.where(target_data[:,0] == name))\n",
    "# Make sure the dimentions are right\n",
    "sorted_cofs = np.squeeze(sorted_cofs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we are organized, remove the names from the targets\n",
    "target_data = target_data[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shift the training data using the new indeces\n",
    "db_traindata = db_traindata[sorted_cofs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOW you would want to make cold and warm batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_traindata_cold = db_traindata[obj['ids_graphs_cold']]\n",
    "db_traindata_warm = db_traindata[obj['ids_graphs_warm']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_data_cold = target_data[obj['ids_graphs_cold']] \n",
    "target_data_warm = target_data[obj['ids_graphs_warm']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_mask = obj['masks']['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.multiply(train_masks[1],target_data_warm)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.428440000000001e-05, 0.000114672, 3.49334e-05,\n",
       "       3.3294200000000004e-05, 2.7062899999999998e-05, 5.55429e-05,\n",
       "       4.73722e-05, 0.0014552, 9.35926e-05, 0.000168302,\n",
       "       2.0753899999999998e-05, 1.14166e-05, 4.2636e-05, 1.18783e-05,\n",
       "       3.29302e-05, 1.87006e-05, 5.19729e-05, 4.18379e-05, 4.89429e-05,\n",
       "       1.7079e-05, 8.031399999999999e-05, 4.3941400000000006e-05,\n",
       "       2.57802e-05, 3.5383400000000004e-05, 0.00010005100000000001,\n",
       "       6.09999e-05, 4.79526e-05, 2.6399699999999997e-05,\n",
       "       3.2759400000000004e-05, 6.144439999999999e-05, 3.99435e-05,\n",
       "       4.48509e-05, 3.84352e-05, 2.09692e-05, 2.41475e-05, 8.04017e-05,\n",
       "       4.31768e-05, 0.00132955, 0.000117988, 0.000134237,\n",
       "       2.6611900000000002e-05, 1.62172e-05, 3.71527e-05, 2.52684e-05,\n",
       "       2.25688e-05, 4.46037e-05, 2.01106e-05, 5.2531700000000004e-05,\n",
       "       3.64921e-05, 4.02127e-05, 9.794940000000001e-05, 4.43404e-05,\n",
       "       3.92503e-05, 2.26667e-05, 2.7729200000000002e-05, 3.06251e-05,\n",
       "       3.6526399999999996e-05, 4.2687e-05, 6.0033999999999995e-05,\n",
       "       2.71931e-05, 2.7431799999999997e-05, 5.187e-05, 2.72e-05,\n",
       "       2.17296e-05, 1.4690899999999999e-05, 7.28494e-05, 2.16002e-05,\n",
       "       6.115689999999999e-05, 6.48963e-05, 2.07134e-05, 2.76701e-05,\n",
       "       3.4766e-05, 5.70571e-05, 8.726540000000001e-05, 0.00013231,\n",
       "       0.00042296300000000005, 1.0285699999999999e-05, 2.30512e-05,\n",
       "       2.05463e-05, 1.75522e-05, 5.47504e-05, 5.6889700000000005e-05,\n",
       "       5.7801800000000006e-05, 4.65639e-05, 3.83861e-05, 2.04761e-05,\n",
       "       0.000174035, 2.72548e-05, 2.0707399999999998e-05, 4.8075e-05,\n",
       "       4.63542e-05, 5.30365e-05, 6.16845e-05, 0.0008184560000000001,\n",
       "       7.64851e-05, 8.502299999999999e-05, 1.7921e-05, 3.07459e-05,\n",
       "       2.74108e-05, 3.20623e-05, 3.48573e-05, 2.2942600000000003e-05,\n",
       "       2.68985e-05, 0.000116784, 0.000531553, 4.41857e-05, 2.60246e-05,\n",
       "       2.1377600000000003e-05, 8.08578e-05, 0.000339402,\n",
       "       8.960350000000001e-05, 1.95221e-05, 7.585529999999999e-05,\n",
       "       3.1504499999999996e-05, 6.82468e-05, 1.73448e-05, 5.89621e-05,\n",
       "       0.000131739, 5.91794e-05, 6.87031e-05, 2.51988e-05,\n",
       "       4.9448500000000006e-05, 4.93742e-05, 3.1198699999999997e-05,\n",
       "       5.69337e-05, 3.16465e-05, 0.000478422, 1.87557e-05, 6.11127e-05,\n",
       "       0.000138741, 4.0654499999999995e-05, 0.000121602,\n",
       "       2.8034699999999998e-05, 0.000478999, 0.00097256,\n",
       "       4.6752600000000004e-05, 4.3458500000000004e-05, 4.1211e-05,\n",
       "       0.000378552, 4.389560000000001e-05, 0.000122035,\n",
       "       2.5602199999999997e-05, 1.84835e-05, 4.38439e-05,\n",
       "       0.00011338799999999999, 3.01289e-05, 5.88184e-05, 6.70184e-05,\n",
       "       0.00010934200000000001, 1.1288599999999999e-05, 2.05245e-05,\n",
       "       0.00072095, 4.88868e-05, 4.06302e-05, 7.20881e-05, 3.87835e-05,\n",
       "       4.2364700000000005e-05, 8.821379999999999e-05, 2.72367e-05,\n",
       "       0.000119175, 1.92626e-05, 2.63367e-05, 5.8546400000000006e-05,\n",
       "       0.000510228, 7.09297e-05, 2.8880300000000002e-05,\n",
       "       0.00017554900000000002, 2.31903e-05, 8.906e-05, 5.56526e-05,\n",
       "       2.81213e-05, 5.2781599999999996e-05, 1.46155e-05, 4.39286e-05,\n",
       "       3.07558e-05, 1.93967e-05, 3.7138299999999996e-05, 1.96079e-05,\n",
       "       9.52892e-05, 0.000148295, 0.000364756, 6.85507e-05, 3.87438e-05,\n",
       "       2.07422e-05, 2.8133499999999998e-05, 0.00011708299999999999,\n",
       "       0.000124994, 5.9808599999999995e-05, 5.243399999999999e-05,\n",
       "       1.8275499999999998e-05, 2.5090500000000003e-05,\n",
       "       2.0713499999999997e-05, 0.000173895, 0.000146888,\n",
       "       2.6658400000000002e-05, 0.000112145, 4.54756e-05,\n",
       "       5.3486700000000004e-05, 5.50566e-05, 2.78743e-05, 5.24785e-05,\n",
       "       0.000136474, 7.32236e-05, 1.72752e-05, 8.42315e-05, 0.000885316,\n",
       "       6.27998e-05, 0.00126503, 1.71149e-05, 5.15686e-05, 3.2834e-05,\n",
       "       5.0209899999999995e-05, 0.000226905, 0.000171293,\n",
       "       8.261299999999999e-05, 9.2208e-05, 3.76129e-05,\n",
       "       7.698710000000001e-05, 6.35705e-05, 0.000448636, 8.43293e-05],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seperate Training and Testing Sets TODO - write more asserts in final draft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now prepare empty arrays that will hold the training set, and testing set, for each target and each split\n",
    "train_inputs = np.empty((10,16), dtype=object)\n",
    "test_inputs = np.empty((10,16), dtype=object)\n",
    "train_outputs = np.empty((10,16), dtype=object)\n",
    "test_outputs = np.empty((10,16), dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    for j in range(16):\n",
    "        train_ones = np.where(train_masks[i][:,j] == 1)[0]\n",
    "        train_inputs = np.array([db_traindata_warm[i] for i in train_ones],dtype=np.float64)\n",
    "        train_outputs = np.multiply(train_masks[i],target_data_warm)[:,j]\n",
    "        train_outputs = train_outputs[train_outputs != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    for j in range(16):\n",
    "        test_inputs = db_traindata_cold\n",
    "        test_outputs = target_data_cold[:,j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114, 19)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.8474982722326, 2.7859601515990002, 5.0505034785015,\n",
       "       4.5589461404299, 4.0637463902337005, 3.1214879603067005,\n",
       "       2.5139844068395, 2.9967296885762, 3.1718324877059, 3.8030312922664,\n",
       "       6.333711910192701, 2.2688428990166, 3.8246274921351997,\n",
       "       7.2997999250009, 2.5265275973688, 2.9794002185602997,\n",
       "       2.1684461820015, 3.5402912375002002, 3.6724612389813,\n",
       "       2.6892693971816004, 3.0572384067628997, 1.3046221095407,\n",
       "       3.8135024157846003, 4.6175211170326, 2.7478683863385998,\n",
       "       3.2982030877078996, 3.785015742887, 1.6776968134673,\n",
       "       3.9202134219472997, 3.3078260395607995, 3.5877602298357005,\n",
       "       3.7913155336097004, 3.0427115741508994, 4.821859897581599,\n",
       "       3.2221231316053, 3.2046239541657995, 4.5017060724121,\n",
       "       0.8979819117370799, 3.1070862435096003, 5.663239339727401,\n",
       "       3.1571453204301, 3.3476726420402003, 3.3025931276775005,\n",
       "       3.6843639567653, 5.4835640700034, 4.2734565253485,\n",
       "       6.1679205396709005, 2.5372885967363996, 5.7408067328167,\n",
       "       3.4513210448328002, 3.1622447902756, 3.3430561937700998,\n",
       "       3.1241835396043998, 3.9727674866000005, 5.018803105412901,\n",
       "       2.4764742053952005, 2.0198970174121, 3.8356980604859,\n",
       "       3.3585788657044, 5.431219488850501, 5.952673121390999,\n",
       "       3.2537377558383, 3.4868600018816, 1.5552088981738998,\n",
       "       3.3901213396034, 4.6865159648310994, 3.0383745677302003,\n",
       "       4.483052890574401, 3.2213917530734997, 2.9362176885473996,\n",
       "       3.0593589999567, 2.0978011263556997, 3.1718943026977997,\n",
       "       2.5813664663264, 0.71666777742972, 2.3083792676577,\n",
       "       2.5268826874094, 1.6821533242388, 3.4126588991799998,\n",
       "       3.8611735242144, 1.7358336102698002, 3.979180370815,\n",
       "       3.3527824329506, 2.6817255951343997, 6.8310061571426,\n",
       "       9.772321439545, 2.6539075944965, 2.6225478417631, 4.0519677986796,\n",
       "       3.0125019657576, 3.2498460479128997, 3.0942704156768,\n",
       "       2.1324816078336, 2.9262470156730003, 3.8627093462987,\n",
       "       3.5992028193838, 3.1679968700355, 2.662031959262, 2.6012254592139,\n",
       "       3.0481136639272006, 4.3628483891418, 3.6223197860333998,\n",
       "       2.9376272021387004, 3.2238997376575, 3.6811837378685,\n",
       "       2.2427543219021002, 2.9067984557454998, 3.3671445796394996,\n",
       "       2.604812288531, 3.460134138732, 3.6327063928927004,\n",
       "       3.2516073763080002, 3.3654489528185, 3.4504074978048997],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(221, 19)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(221,)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_outputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each index, since correlated to a target, will have a mean, and absolute deviation\n",
    "means = np.empty((10,16), dtype=np.float64)\n",
    "stdevs = np.empty((10,16), dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-88-f895f89be2a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mmeans\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0mstdevs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'float' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# Calculate the mean and stdevs, then push into the corresponding slot\n",
    "for i in range(10):\n",
    "    for j in range(16):\n",
    "        means[i][j] = train_outputs[i][j].mean()\n",
    "        stdevs[i][j] = np.std(train_outputs[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create arrays to store the standardized (z-score) version of the training and testing outputs\n",
    "train_outputs_z = np.empty((10,16), dtype=object)\n",
    "test_outputs_z = np.empty((10,16), dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Standardization Procedure, dimentions of outputs do not change\n",
    "for i in range(10):\n",
    "    for j in range(16):\n",
    "        train_outputs_z[i][j] = (train_outputs[i][j] - means[i][j]) / stdevs[i][j]\n",
    "        test_outputs_z[i][j] = (test_outputs[i][j] - means[i][j]) / stdevs[i][j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a variable of the target names for ease of printing\n",
    "target_name = ['h2o_henry', 'h2s_henry', 'xe_henry', 'kr_henry', 'co2_0.001bar', 'o2_5bar', 'o2_140bar', 'co2_30bar', 'n2_0.001bar', 'n2_30bar', 'h2_77K_5bar', 'h2_77K_100bar', \n",
    "            'h2_298K_5bar', 'h2_298K_100bar', 'ch4_65bar', 'ch4_5.8bar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ready to store all of the performance metric for each test that is run\n",
    "MAEs = np.empty((10,16), dtype=np.float64)\n",
    "SPRs = np.empty((10,16), dtype=np.float64)\n",
    "MSEs = np.empty((10,16), dtype=np.float64)\n",
    "RMSEs = np.empty((10,16), dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now run all 10 x 16 tests in sequence, using the test and train splits we made\n",
    "for i in range(10):\n",
    "    # Print the epoch to get some idea of what is going on\n",
    "    print(\"Epoch: \", i)\n",
    "    for j in range(16):\n",
    "        # Instanciate the model, baseline model taken from another project (for now)\n",
    "        Random_Forest = ExtraTreesRegressor(n_estimators = 200, random_state = 0, criterion = \"mae\", bootstrap = True, warm_start = True)\n",
    "        # Fit the model using the inputs and zscored outputs\n",
    "        Random_Forest.fit(train_inputs[i][j], train_outputs_z[i][j])\n",
    "        # Make predictions using test inputs\n",
    "        test_preds = Random_Forest.predict(test_inputs[i][j])\n",
    "        # Find the metrics\n",
    "        MAEs[i][j] = metrics.mean_absolute_error(test_outputs_z[i][j], test_preds)\n",
    "        SPRs[i][j] = spearmanr(test_outputs_z[i][j], test_preds)[0]\n",
    "        MSEs[i][j] = metrics.mean_squared_error(test_outputs_z[i][j], test_preds)\n",
    "        RMSEs[i][j] = np.sqrt(metrics.mean_squared_error(test_preds, test_outputs_z[i][j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take averages over the 10 runs for each target\n",
    "MAEs = MAEs.mean(axis=0)\n",
    "SPRs = SPRs.mean(axis=0)\n",
    "MSEs = MSEs.mean(axis=0)\n",
    "RMSEs = RMSEs.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Tell the user what is going on\n",
    "for i in range(16):\n",
    "    print(\"Printing Details for Target: \", target_name[i])\n",
    "    print(\"---------------------------\")\n",
    "    print(\"Average MAE: \", MAEs[i])\n",
    "    print(\"Average MSE: \", MSEs[i])\n",
    "    print(\"Average SPR: \", SPRs[i])\n",
    "    print(\"Average RMSE: \", RMSEs[i])\n",
    "    print(\"________________________________________________\\n\\n\")\n",
    "    \n",
    "print(\"Overall Averages\")\n",
    "print(\"****************************************\")\n",
    "print(\"MAE: \", MAEs.mean())\n",
    "print(\"MSE: \", MSEs.mean())\n",
    "print(\"SPR: \", SPRs.mean())\n",
    "print(\"RMSE: \", RMSEs.mean())\n",
    "print(\"***************************************:)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
